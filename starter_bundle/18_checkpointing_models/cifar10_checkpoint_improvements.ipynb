{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNLKS87hBSrOJV3dLC1Oab2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import BatchNormalization\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers.core import Activation, Flatten, Dropout, Dense\n","from keras import backend as K\n","\n","\n","class MiniVGGNet:\n","    @staticmethod\n","    def build(width, height, depth, classes):\n","        model = Sequential()\n","        if K.image_data_format() == \"channels_first\":\n","            input_shape = (depth, height, width)\n","            chan_dim = 1\n","        else:\n","            input_shape = (height, width, depth)\n","            chan_dim = -1\n","\n","        # first CONV => RELU => CONV => RELU => POOL layer set\n","        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chan_dim))\n","        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chan_dim))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(0.25))\n","\n","        # second CONV => RELU => CONV => RELU => POOL layer set\n","        model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=input_shape))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chan_dim))\n","        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(axis=chan_dim))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","        model.add(Dropout(0.25))\n","\n","        # First and only set of FC => RELU layers\n","        model.add(Flatten())\n","        model.add(Dense(512))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization())\n","        model.add(Dropout(0.5))\n","\n","        # softmax classifier\n","        model.add(Dense(classes))\n","        model.add(Activation(\"softmax\"))\n","\n","        return model"],"metadata":{"id":"SG3Jg89_odWz","executionInfo":{"status":"ok","timestamp":1690214585837,"user_tz":-60,"elapsed":5682,"user":{"displayName":"Joseph Sykes","userId":"13195148787507540165"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelBinarizer\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import SGD\n","from keras.datasets import cifar10"],"metadata":{"id":"Zif_v8lzootA","executionInfo":{"status":"ok","timestamp":1690214589513,"user_tz":-60,"elapsed":1736,"user":{"displayName":"Joseph Sykes","userId":"13195148787507540165"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["print(\"[INFO] loading CIFAR-10 data...\")\n","((trainX, trainY), (testX, testY)) = cifar10.load_data()\n","trainX = trainX.astype(\"float\") / 255.0\n","testX = testX.astype(\"float\") / 255.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZmuE3Lyo09Z","executionInfo":{"status":"ok","timestamp":1690214601139,"user_tz":-60,"elapsed":7825,"user":{"displayName":"Joseph Sykes","userId":"13195148787507540165"}},"outputId":"9d44392b-d646-4775-e6c7-34e4ed696571"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] loading CIFAR-10 data...\n","Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 3s 0us/step\n"]}]},{"cell_type":"code","source":["lb = LabelBinarizer()\n","trainY = lb.fit_transform(trainY)\n","testY = lb.fit_transform(testY)\n","\n","print(\"[INFO] compiling model...\")\n","opt = SGD(learning_rate=0.01, decay=0.01 / 40, momentum=0.9, nesterov=True)\n","model = MiniVGGNet.build(width=32, height=32, depth=3, classes=10)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2S4S9Hz2o12U","executionInfo":{"status":"ok","timestamp":1690214627137,"user_tz":-60,"elapsed":4661,"user":{"displayName":"Joseph Sykes","userId":"13195148787507540165"}},"outputId":"87a5be6c-ef01-4fdc-a389-25d50483b83f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] compiling model...\n"]}]},{"cell_type":"code","source":["fname = \"/content/weights/weights-{epoch:03d}-{val_loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(fname, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n","callbacks = [checkpoint]\n","\n","print(\"[INFO] training network...\")\n","H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=40, callbacks=callbacks, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFOFrI2MpGqf","executionInfo":{"status":"ok","timestamp":1690215122031,"user_tz":-60,"elapsed":384703,"user":{"displayName":"Joseph Sykes","userId":"13195148787507540165"}},"outputId":"4ee4b297-c402-43d8-bd25-19ee846c5a42"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] training network...\n","Epoch 1/40\n","782/782 [==============================] - ETA: 0s - loss: 1.6723 - accuracy: 0.4401\n","Epoch 1: val_loss improved from inf to 1.43382, saving model to /content/weights/weights-001-1.4338.hdf5\n","782/782 [==============================] - 19s 13ms/step - loss: 1.6723 - accuracy: 0.4401 - val_loss: 1.4338 - val_accuracy: 0.5026\n","Epoch 2/40\n","780/782 [============================>.] - ETA: 0s - loss: 1.1641 - accuracy: 0.5936\n","Epoch 2: val_loss improved from 1.43382 to 1.13162, saving model to /content/weights/weights-002-1.1316.hdf5\n","782/782 [==============================] - 10s 12ms/step - loss: 1.1638 - accuracy: 0.5936 - val_loss: 1.1316 - val_accuracy: 0.6152\n","Epoch 3/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.9576 - accuracy: 0.6678\n","Epoch 3: val_loss improved from 1.13162 to 0.94401, saving model to /content/weights/weights-003-0.9440.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9565 - accuracy: 0.6681 - val_loss: 0.9440 - val_accuracy: 0.6682\n","Epoch 4/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.8468 - accuracy: 0.7047\n","Epoch 4: val_loss improved from 0.94401 to 0.74639, saving model to /content/weights/weights-004-0.7464.hdf5\n","782/782 [==============================] - 9s 12ms/step - loss: 0.8469 - accuracy: 0.7046 - val_loss: 0.7464 - val_accuracy: 0.7405\n","Epoch 5/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.7684 - accuracy: 0.7297\n","Epoch 5: val_loss improved from 0.74639 to 0.72107, saving model to /content/weights/weights-005-0.7211.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7688 - accuracy: 0.7297 - val_loss: 0.7211 - val_accuracy: 0.7515\n","Epoch 6/40\n","779/782 [============================>.] - ETA: 0s - loss: 0.7208 - accuracy: 0.7478\n","Epoch 6: val_loss improved from 0.72107 to 0.67154, saving model to /content/weights/weights-006-0.6715.hdf5\n","782/782 [==============================] - 10s 13ms/step - loss: 0.7206 - accuracy: 0.7479 - val_loss: 0.6715 - val_accuracy: 0.7671\n","Epoch 7/40\n","777/782 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.7619\n","Epoch 7: val_loss did not improve from 0.67154\n","782/782 [==============================] - 9s 12ms/step - loss: 0.6705 - accuracy: 0.7620 - val_loss: 0.6877 - val_accuracy: 0.7608\n","Epoch 8/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.6321 - accuracy: 0.7785\n","Epoch 8: val_loss improved from 0.67154 to 0.63108, saving model to /content/weights/weights-008-0.6311.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6322 - accuracy: 0.7785 - val_loss: 0.6311 - val_accuracy: 0.7807\n","Epoch 9/40\n","779/782 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.7886\n","Epoch 9: val_loss did not improve from 0.63108\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6004 - accuracy: 0.7885 - val_loss: 0.6432 - val_accuracy: 0.7798\n","Epoch 10/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.5655 - accuracy: 0.8005\n","Epoch 10: val_loss did not improve from 0.63108\n","782/782 [==============================] - 9s 11ms/step - loss: 0.5657 - accuracy: 0.8004 - val_loss: 0.6320 - val_accuracy: 0.7853\n","Epoch 11/40\n","779/782 [============================>.] - ETA: 0s - loss: 0.5442 - accuracy: 0.8068\n","Epoch 11: val_loss improved from 0.63108 to 0.62308, saving model to /content/weights/weights-011-0.6231.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.5437 - accuracy: 0.8070 - val_loss: 0.6231 - val_accuracy: 0.7891\n","Epoch 12/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.8175\n","Epoch 12: val_loss improved from 0.62308 to 0.59758, saving model to /content/weights/weights-012-0.5976.hdf5\n","782/782 [==============================] - 9s 12ms/step - loss: 0.5165 - accuracy: 0.8174 - val_loss: 0.5976 - val_accuracy: 0.7978\n","Epoch 13/40\n","781/782 [============================>.] - ETA: 0s - loss: 0.4959 - accuracy: 0.8241\n","Epoch 13: val_loss improved from 0.59758 to 0.58441, saving model to /content/weights/weights-013-0.5844.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4959 - accuracy: 0.8241 - val_loss: 0.5844 - val_accuracy: 0.8029\n","Epoch 14/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.4766 - accuracy: 0.8321\n","Epoch 14: val_loss did not improve from 0.58441\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4768 - accuracy: 0.8320 - val_loss: 0.5881 - val_accuracy: 0.8070\n","Epoch 15/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.4607 - accuracy: 0.8370\n","Epoch 15: val_loss improved from 0.58441 to 0.57360, saving model to /content/weights/weights-015-0.5736.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4604 - accuracy: 0.8371 - val_loss: 0.5736 - val_accuracy: 0.8113\n","Epoch 16/40\n","781/782 [============================>.] - ETA: 0s - loss: 0.4443 - accuracy: 0.8419\n","Epoch 16: val_loss improved from 0.57360 to 0.57065, saving model to /content/weights/weights-016-0.5706.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4443 - accuracy: 0.8420 - val_loss: 0.5706 - val_accuracy: 0.8113\n","Epoch 17/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8487\n","Epoch 17: val_loss improved from 0.57065 to 0.55981, saving model to /content/weights/weights-017-0.5598.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4251 - accuracy: 0.8487 - val_loss: 0.5598 - val_accuracy: 0.8142\n","Epoch 18/40\n","777/782 [============================>.] - ETA: 0s - loss: 0.4146 - accuracy: 0.8514\n","Epoch 18: val_loss did not improve from 0.55981\n","782/782 [==============================] - 9s 11ms/step - loss: 0.4145 - accuracy: 0.8514 - val_loss: 0.5859 - val_accuracy: 0.8066\n","Epoch 19/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.4013 - accuracy: 0.8571\n","Epoch 19: val_loss did not improve from 0.55981\n","782/782 [==============================] - 9s 12ms/step - loss: 0.4015 - accuracy: 0.8571 - val_loss: 0.5762 - val_accuracy: 0.8112\n","Epoch 20/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8628\n","Epoch 20: val_loss did not improve from 0.55981\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3873 - accuracy: 0.8628 - val_loss: 0.5653 - val_accuracy: 0.8158\n","Epoch 21/40\n","777/782 [============================>.] - ETA: 0s - loss: 0.3738 - accuracy: 0.8644\n","Epoch 21: val_loss improved from 0.55981 to 0.55438, saving model to /content/weights/weights-021-0.5544.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3740 - accuracy: 0.8644 - val_loss: 0.5544 - val_accuracy: 0.8181\n","Epoch 22/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.8716\n","Epoch 22: val_loss did not improve from 0.55438\n","782/782 [==============================] - 9s 12ms/step - loss: 0.3623 - accuracy: 0.8716 - val_loss: 0.5705 - val_accuracy: 0.8175\n","Epoch 23/40\n","777/782 [============================>.] - ETA: 0s - loss: 0.3544 - accuracy: 0.8731\n","Epoch 23: val_loss did not improve from 0.55438\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3551 - accuracy: 0.8729 - val_loss: 0.5662 - val_accuracy: 0.8176\n","Epoch 24/40\n","779/782 [============================>.] - ETA: 0s - loss: 0.3401 - accuracy: 0.8779\n","Epoch 24: val_loss improved from 0.55438 to 0.54737, saving model to /content/weights/weights-024-0.5474.hdf5\n","782/782 [==============================] - 9s 12ms/step - loss: 0.3402 - accuracy: 0.8778 - val_loss: 0.5474 - val_accuracy: 0.8229\n","Epoch 25/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.8808\n","Epoch 25: val_loss did not improve from 0.54737\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3334 - accuracy: 0.8808 - val_loss: 0.5937 - val_accuracy: 0.8161\n","Epoch 26/40\n","779/782 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.8818\n","Epoch 26: val_loss did not improve from 0.54737\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3265 - accuracy: 0.8819 - val_loss: 0.5562 - val_accuracy: 0.8226\n","Epoch 27/40\n","781/782 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.8860\n","Epoch 27: val_loss did not improve from 0.54737\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3201 - accuracy: 0.8861 - val_loss: 0.5540 - val_accuracy: 0.8231\n","Epoch 28/40\n","782/782 [==============================] - ETA: 0s - loss: 0.3119 - accuracy: 0.8891\n","Epoch 28: val_loss did not improve from 0.54737\n","782/782 [==============================] - 9s 11ms/step - loss: 0.3119 - accuracy: 0.8891 - val_loss: 0.5479 - val_accuracy: 0.8253\n","Epoch 29/40\n","782/782 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.8932\n","Epoch 29: val_loss did not improve from 0.54737\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2994 - accuracy: 0.8932 - val_loss: 0.5528 - val_accuracy: 0.8244\n","Epoch 30/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.2980 - accuracy: 0.8927\n","Epoch 30: val_loss improved from 0.54737 to 0.54553, saving model to /content/weights/weights-030-0.5455.hdf5\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2979 - accuracy: 0.8927 - val_loss: 0.5455 - val_accuracy: 0.8265\n","Epoch 31/40\n","782/782 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.8985\n","Epoch 31: val_loss did not improve from 0.54553\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2853 - accuracy: 0.8985 - val_loss: 0.5508 - val_accuracy: 0.8242\n","Epoch 32/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.8979\n","Epoch 32: val_loss did not improve from 0.54553\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2825 - accuracy: 0.8979 - val_loss: 0.5521 - val_accuracy: 0.8235\n","Epoch 33/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 0.9016\n","Epoch 33: val_loss did not improve from 0.54553\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2765 - accuracy: 0.9016 - val_loss: 0.5576 - val_accuracy: 0.8227\n","Epoch 34/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9028\n","Epoch 34: val_loss did not improve from 0.54553\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2671 - accuracy: 0.9027 - val_loss: 0.5506 - val_accuracy: 0.8280\n","Epoch 35/40\n","782/782 [==============================] - ETA: 0s - loss: 0.2676 - accuracy: 0.9055\n","Epoch 35: val_loss improved from 0.54553 to 0.54468, saving model to /content/weights/weights-035-0.5447.hdf5\n","782/782 [==============================] - 10s 12ms/step - loss: 0.2676 - accuracy: 0.9055 - val_loss: 0.5447 - val_accuracy: 0.8270\n","Epoch 36/40\n","778/782 [============================>.] - ETA: 0s - loss: 0.2614 - accuracy: 0.9065\n","Epoch 36: val_loss did not improve from 0.54468\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2614 - accuracy: 0.9066 - val_loss: 0.5486 - val_accuracy: 0.8278\n","Epoch 37/40\n","781/782 [============================>.] - ETA: 0s - loss: 0.2561 - accuracy: 0.9084\n","Epoch 37: val_loss improved from 0.54468 to 0.54314, saving model to /content/weights/weights-037-0.5431.hdf5\n","782/782 [==============================] - 9s 12ms/step - loss: 0.2561 - accuracy: 0.9084 - val_loss: 0.5431 - val_accuracy: 0.8306\n","Epoch 38/40\n","777/782 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.9112\n","Epoch 38: val_loss did not improve from 0.54314\n","782/782 [==============================] - 9s 12ms/step - loss: 0.2474 - accuracy: 0.9113 - val_loss: 0.5522 - val_accuracy: 0.8277\n","Epoch 39/40\n","780/782 [============================>.] - ETA: 0s - loss: 0.2512 - accuracy: 0.9095\n","Epoch 39: val_loss did not improve from 0.54314\n","782/782 [==============================] - 10s 12ms/step - loss: 0.2512 - accuracy: 0.9095 - val_loss: 0.5494 - val_accuracy: 0.8313\n","Epoch 40/40\n","781/782 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9130\n","Epoch 40: val_loss did not improve from 0.54314\n","782/782 [==============================] - 9s 11ms/step - loss: 0.2426 - accuracy: 0.9130 - val_loss: 0.5448 - val_accuracy: 0.8312\n"]}]}]}