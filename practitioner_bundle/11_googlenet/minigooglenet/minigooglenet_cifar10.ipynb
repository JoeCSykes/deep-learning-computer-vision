{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["u9j6tmEGHSCO","dko4DD8EHehb","KpPm9xwnHu6P","UIkCYrjaIc9h","GDCPLk17IWqU"],"authorship_tag":"ABX9TyN8fz7HRfyMh/Nx6iZybJZC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"-XL0hpYVHC4J"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelBinarizer\n","from keras.callbacks import LearningRateScheduler\n","from keras.optimizers import SGD\n","from keras.datasets import cifar10\n","import numpy as np\n","import argparse\n","import os"],"metadata":{"id":"oX0xygBEG9vl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"haow6eWxHKsl"}},{"cell_type":"markdown","source":["#### MiniGoogleNet Model"],"metadata":{"id":"u9j6tmEGHSCO"}},{"cell_type":"code","source":["from keras.layers import BatchNormalization, Conv2D, AveragePooling2D, MaxPooling2D, Activation, Dropout, Dense, \\\n","    Flatten, Input, concatenate\n","from keras.models import Model\n","from keras import backend as K\n","\n","\n","class MiniGoogleNet:\n","\n","    @staticmethod\n","    def conv_module(x, k, k_x, k_y, stride, chan_dim, padding=\"same\"):\n","        \"\"\"\n","        Module to apply 2D convolution layer followed by an activation layer and finally a batch normalization layer\n","        :param x: input layer\n","        :param k: num filters for conv layer to learn\n","        :param k_x: size of x-axis of K filters to learn\n","        :param k_y: size of y-axis of K filters to learn\n","        :param stride: stride of conv layer\n","        :param chan_dim: channel dimension (derived from channels last or channels first ordering)\n","        :param padding: type of padding to be applied to conv layer\n","        :return: Keras layer\n","        \"\"\"\n","        # def a CONV => RELU => BN pattern\n","        x = Conv2D(k, (k_x, k_y), strides=stride, padding=padding)(x)\n","        x = Activation(\"relu\")(x)\n","        x = BatchNormalization(axis=chan_dim)(x)\n","\n","        return x\n","\n","    @staticmethod\n","    def inception_module(x, num_k_1x1, num_k_3x3, chan_dim):\n","        \"\"\"\n","        Module to generate the mini inception module which applies a 1x1 conv_module and a 3x3 conv_module in parallel\n","        to the input and then merges the 2 results across the channel dimension to form the output\n","        :param x: input layer\n","        :param num_k_1x1: num 1x1 conv filters to generate\n","        :param num_k_3x3: num 3x3 conv filters to generate\n","        :param chan_dim: channel dimension (derived from channels last or channels first ordering)\n","        :return: Keras layer\n","        \"\"\"\n","        conv_1x1 = MiniGoogleNet.conv_module(x, num_k_1x1, 1, 1, (1, 1), chan_dim)\n","        conv_3x3 = MiniGoogleNet.conv_module(x, num_k_3x3, 3, 3, (1, 1), chan_dim)\n","        x = concatenate([conv_1x1, conv_3x3], axis=chan_dim)\n","\n","        return x\n","\n","    @staticmethod\n","    def downsample_module(x, k, chan_dim):\n","        \"\"\"\n","        Module to decrease the output volume size. Two methods are applied in parallel and the results are then\n","        merged together. The first down-sampling method is a 3x3 conv layer with a stride of 2x2 and the second is a\n","        max pooling layer with a 3x3 window and a stride of 2x2.\n","        :param x: input layer\n","        :param k: num filters\n","        :param chan_dim: channel dimension (derived from channels last or channels first ordering)\n","        :return: Keras layer\n","        \"\"\"\n","        conv_3x3 = MiniGoogleNet.conv_module(x, k, 3, 3, (2, 2), chan_dim, padding=\"valid\")\n","        pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","        x = concatenate([conv_3x3, pool], axis=chan_dim)\n","\n","        return x\n","\n","    @staticmethod\n","    def build(width, height, depth, classes):\n","        inputShape = (height, width, depth)\n","        chan_dim = -1\n","\n","        if K.image_data_format() == \"channels_first\":\n","            inputShape = (depth, height, width)\n","            chan_dim = 1\n","\n","        inputs = Input(shape=inputShape)\n","        x = MiniGoogleNet.conv_module(inputs, 96, 3, 3, (1, 1), chan_dim)\n","\n","        x = MiniGoogleNet.inception_module(x, 32, 32, chan_dim)\n","        x = MiniGoogleNet.inception_module(x, 32, 48, chan_dim)\n","        x = MiniGoogleNet.downsample_module(x, 80, chan_dim)\n","\n","        x = MiniGoogleNet.inception_module(x, 112, 48, chan_dim)\n","        x = MiniGoogleNet.inception_module(x, 96, 64, chan_dim)\n","        x = MiniGoogleNet.inception_module(x, 80, 80, chan_dim)\n","        x = MiniGoogleNet.inception_module(x, 48, 96, chan_dim)\n","        x = MiniGoogleNet.downsample_module(x, 96, chan_dim)\n","\n","        x = MiniGoogleNet.inception_module(x, 176, 160, chan_dim)\n","        x = MiniGoogleNet.inception_module(x, 176, 160, chan_dim)\n","        x = AveragePooling2D((7, 7))(x)\n","        x = Dropout(0.5)(x)\n","\n","        x = Flatten()(x)\n","        x = Dense(classes)(x)\n","        x = Activation(\"softmax\")(x)\n","\n","        model = Model(inputs, x, name=\"minigooglenet\")\n","\n","        return model\n"],"metadata":{"id":"e0uyV3sfHJsg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Monitor"],"metadata":{"id":"dko4DD8EHehb"}},{"cell_type":"code","source":["from keras.callbacks import BaseLogger\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import json\n","\n","\n","class TrainingMonitor(BaseLogger):\n","    def __init__(self, fig_path=None, json_path=None, start_at=0, start_graph_at=0):\n","        super(TrainingMonitor, self).__init__()\n","        self.fig_path = fig_path\n","        self.json_path = json_path\n","        self. start_at = start_at\n","        self.start_graph_at = start_graph_at\n","        self.H = {}\n","\n","    def on_train_begin(self, logs={}):\n","\n","        if self.json_path:\n","            if os.path.exists(self.json_path):\n","                self.H = json.loads(open(self.json_path).read())\n","\n","                # trim any entries that are past the starting epoch\n","                if self.start_at > 0:\n","                    for k in self.H.keys():\n","                        self.H[k] = self.H[k][:self.start_at]\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        for (k, v) in logs.items():\n","            log = self.H.get(k, [])\n","            log.append(v)\n","            self.H[k] = log\n","\n","        if self.json_path:\n","            with open(self.json_path, \"w\") as file:\n","                file.write(json.dumps(self.H))\n","\n","        if len(self.H[\"loss\"]) > self.start_graph_at + 1:\n","            x_val = np.arange(0, len(self.H[\"loss\"][self.start_graph_at:]))\n","            plt.style.use(\"ggplot\")\n","            plt.figure()\n","            plt.plot(x_val, self.H[\"loss\"][self.start_graph_at:], label=\"train_loss\")\n","            plt.plot(x_val, self.H[\"val_loss\"][self.start_graph_at:], label=\"val_loss\")\n","            plt.plot(x_val, self.H[\"accuracy\"][self.start_graph_at:], label=\"train_acc\")\n","            plt.plot(x_val, self.H[\"val_accuracy\"][self.start_graph_at:], label=\"val_acc\")\n","            plt.title(f\"Training Loss and Accuracy [Epoch {len(self.H['loss'])}]\")\n","            plt.xlabel(\"Epoch #\")\n","            plt.ylabel(\"Loss / Accuracy\")\n","            plt.legend()\n","\n","            if self.fig_path:\n","                plt.savefig(self.fig_path)\n","                plt.close()\n","            else:\n","                plt.show()\n"],"metadata":{"id":"kIB4gfFNHlTc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Augmentor"],"metadata":{"id":"KpPm9xwnHu6P"}},{"cell_type":"code","source":["!pip install keras_core\n","!pip install keras_cv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AG13Q1t2H-2R","executionInfo":{"status":"ok","timestamp":1701100443156,"user_tz":0,"elapsed":11280,"user":{"displayName":"Joseph Sykes","userId":"13195148787507540165"}},"outputId":"f6e37359-2c98-4088-f03c-050df365afc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras_core in /usr/local/lib/python3.10/dist-packages (0.1.7)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_core) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_core) (1.23.5)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_core) (13.7.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras_core) (0.0.7)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_core) (3.9.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_core) (0.1.8)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_core) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_core) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_core) (0.1.2)\n","Requirement already satisfied: keras_cv in /usr/local/lib/python3.10/dist-packages (0.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (23.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.6.3)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.3)\n","Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.1.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.23.5)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.0.7)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n","Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n","Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.5.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.31.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (4.66.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.1.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.5.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv) (2023.7.22)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.61.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n"]}]},{"cell_type":"code","source":["from keras import Sequential\n","from keras_cv.layers import RandomFlip, RandomRotation, RandomTranslation, RandomZoom, RandomShear\n","\n","\n","class DataAugmentor:\n","\n","    @staticmethod\n","    def build(model):\n","        data_augmentation = Sequential([\n","            RandomRotation(0.1),\n","            RandomTranslation(height_factor=0.1, width_factor=0.1),\n","            RandomShear(0.2),\n","            RandomZoom(0.2),\n","            RandomFlip(\"horizontal\"),\n","        ])\n","\n","        model = Sequential([data_augmentation, model])\n","\n","        return model\n"],"metadata":{"id":"DrhHgwQxH35C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Polynomial Decay"],"metadata":{"id":"UIkCYrjaIc9h"}},{"cell_type":"code","source":["def poly_decay(epoch):\n","    max_epochs = NUM_EPOCHS\n","    base_lr = INIT_lR\n","    # power of 1 gives linear decay, increasing power increases initial and lessens final rate of decay\n","    power = 1.0\n","\n","    alpha = base_lr * (1 - (epoch / float(max_epochs))) ** power\n","\n","    return alpha"],"metadata":{"id":"atvaoZLjIjtL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main"],"metadata":{"id":"GDCPLk17IWqU"}},{"cell_type":"code","source":["NUM_EPOCHS = 70\n","INIT_lR = 1e-2\n","\n","args = {}\n","args[\"model\"] = \"/content/minigooglenet_cifar_10.keras\"\n","args[\"output\"] = \"/content/output\"\n","\n","print(\"[INFO loading CIFAR-10 data...\")\n","((trainX, trainY), (testX, testY)) = cifar10.load_data()\n","trainX = trainX.astype(\"float\")\n","testX = testX.astype(\"float\")\n","\n","# apply mean subtraction\n","mean = np.mean(trainX, axis=0)\n","trainX -= mean\n","testX -= mean\n","\n","lb = LabelBinarizer()\n","trainY = lb.fit_transform(trainY)\n","testY = lb.transform(testY)\n","\n","# construct callbacks\n","fig_path = os.path.sep.join([args[\"output\"], \"{}.png\".format(os.getpid())])\n","json_path = os.path.sep.join([args[\"output\"], \"{}.json\".format(os.getpid())])\n","callbacks = [TrainingMonitor(fig_path, json_path=json_path), LearningRateScheduler(poly_decay)]\n","\n","print(\"[INFO] compiling model...\")\n","opt = SGD(learning_rate=INIT_lR, momentum=0.9)\n","model = MiniGoogleNet.build(width=32, height=32, depth=3, classes=10)\n","model = DataAugmentor.build(model)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","print(\"[INFO] training network...\")\n","model.fit(trainX, trainY, batch_size=64, validation_data=(testX, testY),\n","          epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)\n","print(\"[INFO] serializing network...\")\n","model.save(args[\"model\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnmU80AzIVne","outputId":"6da630d4-a5e2-478f-c287-059c178f277a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO loading CIFAR-10 data...\n","[INFO] compiling model...\n","[INFO] training network...\n","Epoch 1/70\n"]}]}]}